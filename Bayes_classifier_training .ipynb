{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2babc3e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc82262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8982fa",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd62d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_FILE = 'SpamData/SpamData/02_Training/train-data.txt'\n",
    "TEST_DATA_FILE = 'SpamData/SpamData/02_Training/test-data.txt'\n",
    "\n",
    "TOKEN_SPAM_PROB_FILE = 'SpamData/SpamData/03_Testing/prob-spam.txt'\n",
    "TOKEN_HAM_PROB_FILE = 'SpamData/SpamData/03_Testing/prob-ham.txt'\n",
    "TOKEN_ALLPROB_FILE = 'SpamData/SpamData/03_Testing/prob-all-tokens.txt'\n",
    "\n",
    "TEST_FEATURES_MATRIX = 'SpamData/SpamData/03_Testing/test-features.txt'\n",
    "TEST_TARGET_FILE = 'SpamData/SpamData/03_Testing/test-target.txt'\n",
    "\n",
    "VOCAB_SIZE = 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a373b7",
   "metadata": {},
   "source": [
    "## txt to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3872f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_train_data = np.loadtxt(TRAIN_DATA_FILE, delimiter=' ', dtype=int)\n",
    "sparse_test_data = np.loadtxt(TEST_DATA_FILE, delimiter=' ', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "231d683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_full_matrix(sparse_matrix, nr_words=VOCAB_SIZE, doc_idx=0, word_idx=1, category_idx=2, freq_idx=3):\n",
    "    \"\"\"\n",
    "    Form a full matrix from a sparse matrix. Returns a pandas dataframe.\n",
    "    Keyword arguments:\n",
    "    sparse_matrix -- numpy array\n",
    "    nr_words -- vocabulary size\n",
    "    doc_idx -- position in the sparse matrix\n",
    "    word_idx -- position in the sparse matrix\n",
    "    category_idx -- position in the sparse matrix\n",
    "    freq_idx -- position in the sparse matrix\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    columns_names = ['DOC_ID'] + ['CATEGORY'] + list(range(0,VOCAB_SIZE))\n",
    "    doc_id_names = np.unique(sparse_matrix[:, 0])\n",
    "    full_matrix = pd.DataFrame(index=doc_id_names, columns=columns_names)\n",
    "    full_matrix.fillna(value=0, inplace=True)\n",
    "    \n",
    "    \n",
    "    for i in range(sparse_matrix.shape[0]):\n",
    "        doc_nr = sparse_matrix[i][doc_idx]\n",
    "        word_id = sparse_matrix[i][word_idx]\n",
    "        category = sparse_matrix[i][category_idx]\n",
    "        occurrence = sparse_matrix[i][freq_idx]\n",
    "        \n",
    "        full_matrix.at[doc_nr, 'DOC_ID'] = doc_nr\n",
    "        full_matrix.at[doc_nr, 'CATEGORY'] = category\n",
    "        full_matrix.at[doc_nr, word_id] = occurrence\n",
    "    \n",
    "    full_matrix.set_index('DOC_ID', inplace=True)\n",
    "        \n",
    "        \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f8d0f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 23.8 s\n",
      "Wall time: 38.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "full_train_data = make_full_matrix(sparse_train_data, nr_words=VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e5b652",
   "metadata": {},
   "source": [
    "### spam prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a9e3635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.310989284824321"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_sum = full_train_data.CATEGORY.sum() / full_train_data.CATEGORY.size\n",
    "prob_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a3cc40",
   "metadata": {},
   "source": [
    "### total number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a57442ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2490</th>\n",
       "      <th>2491</th>\n",
       "      <th>2492</th>\n",
       "      <th>2493</th>\n",
       "      <th>2494</th>\n",
       "      <th>2495</th>\n",
       "      <th>2496</th>\n",
       "      <th>2497</th>\n",
       "      <th>2498</th>\n",
       "      <th>2499</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOC_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3     4     5     6     7     8     9     ...  2490  \\\n",
       "DOC_ID                                                              ...         \n",
       "0          0     0     1     2     1     0     0     3     0     0  ...     0   \n",
       "1          7     1     2     0     1     0     0     1     0     0  ...     0   \n",
       "2          6     1     1     0     1     0     0     1     0     0  ...     0   \n",
       "3          6     0     0     2     4     0     3    14     0     0  ...     0   \n",
       "4          5     1     2     0     1     0     0     1     0     0  ...     0   \n",
       "\n",
       "        2491  2492  2493  2494  2495  2496  2497  2498  2499  \n",
       "DOC_ID                                                        \n",
       "0          0     0     0     0     0     0     0     0     0  \n",
       "1          0     0     0     0     0     0     0     0     0  \n",
       "2          0     0     0     0     0     0     0     0     0  \n",
       "3          0     0     0     0     0     0     0     0     0  \n",
       "4          0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 2500 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_features = full_train_data.loc[:, full_train_data.columns!='CATEGORY']\n",
    "full_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "371cec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_length = full_train_features.sum(axis=1)\n",
    "total_words = email_length.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d78d223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_lengths = email_length[full_train_data.CATEGORY == 1]\n",
    "ham_lengths = email_length[full_train_data.CATEGORY == 0]\n",
    "\n",
    "spam_total_words = spam_lengths.sum()\n",
    "ham_total_words = ham_lengths.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54ffe981",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spam_tokens = full_train_features.loc[full_train_data.CATEGORY == 1]\n",
    "summed_spam_tokens = train_spam_tokens.sum(axis=0) + 1 \n",
    "\n",
    "train_ham_tokens = full_train_features.loc[full_train_data.CATEGORY == 0]\n",
    "summed_ham_tokens = train_ham_tokens.sum(axis=0) + 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9009c8af",
   "metadata": {},
   "source": [
    "# probabilities #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706d1cc9",
   "metadata": {},
   "source": [
    "## P( Token | Spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5a46a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_tokens_spam = summed_spam_tokens / (spam_total_words + VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8926aaf2",
   "metadata": {},
   "source": [
    "## P( Token | Spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4e691b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_tokens_ham = summed_ham_tokens / (ham_total_words + VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1400c4af",
   "metadata": {},
   "source": [
    "## P(Token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9baf219",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_token_all = full_train_features.sum(axis=0) / total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e99d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(TOKEN_ALLPROB_FILE, probs_token_all)\n",
    "np.savetxt(TOKEN_HAM_PROB_FILE, prob_tokens_ham)\n",
    "np.savetxt(TOKEN_SPAM_PROB_FILE, prob_tokens_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d001f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_data = make_full_matrix(sparse_test_data, VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a08fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = full_test_data.loc[:, full_test_data.columns != 'CATEGORY']\n",
    "y_test = full_test_data.CATEGORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef19b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(TEST_TARGET_FILE, y_test)\n",
    "np.savetxt(TEST_FEATURES_MATRIX, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d57580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c26ffa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca61efa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
